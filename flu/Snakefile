# rule preprocess:
#     input:
#         sequences = "pre-processed/vic.aligned.fasta",
#         metadata = "pre-processed/metadata.tsv",
#         sequence_index = "pre-processed/sequence_index.tsv",
#         mutation_summary = "pre-processed/mutation_summary.tsv"
from datetime import datetime

wildcard_constraints:
    flu_type="[AB]",
    segment="\d",
    year="\d\d\d\d",
    strain="[^_/]+",
    segment_name = "[^_/]+"

rule download_clades:
    message: "Downloading clade definitions for {wildcards.strain} from {params.source} -> {output}"
    output:
        "data/clades_{strain}_raw.tsv"
    params:
        source = lambda w: config["builds"][w.strain][w.segment_name][w.reference]["clade_url"]
    shell: "curl {params.source} | sed '/V1A\\tHA1\\t146\\tI/d' >{output}"

rule offset_clades:
    input: 
        "data/clades_{strain}_raw.tsv"
    output:
        "data/clades_{strain}_{segment_name}_{reference}.tsv"
    params:
        offset = lambda w: config["builds"][w.strain][w.segment_name][w.reference]["clade_offset"]
    shell:
        """
        perl -F'\\t' -ne \
            '$F[2]+={params.offset} if $F[1] =~ "nuc"; \
            print join "\\t", @F' \
            {input} \
            >{output}
        """

rule download:
    output: temp("data/download_{flu_type}_{segment_name}_{year}.fasta")
    params: segment_number = lambda w: segment_number(w.segment_name)
    shell:
        "curl -ksSL -o {output} "
        "'https://www.viprbrc.org/brc/api/sequence?"
        "datatype=genome&"
        "completeseq=N&"
        "family=influenza&"
        "flutype={wildcards.flu_type}&"
        "fromyear={wildcards.year}&"
        "toyear={wildcards.year}&"
        "segment={params.segment_number}&"
        "host=human&"
        "metadata=continent,country,date,fluSeason,fluType,host,length,state,strainName&"
        "output=fasta'"

rule clean_download:
    input: "data/download_{flu_type}_{segment_name}_{year}.fasta"
    output: temp("data/cleaned_download_{flu_type}_{segment_name}_{year}.fasta")
    shell:
        """
        if [ $(wc -l < {input}) -lt 2 ]
        then
            touch {output}
        else
            cp {input} {output}
        fi
        """

rule join_downloads:
    input:
        expand("data/cleaned_download_{{flu_type}}_{{segment_name}}_{year}.fasta",year=range(1989,2022))
    output: "data/download_{flu_type}_{segment_name}.fasta"
    shell: "cat {input} >> {output}"

rule parse:
    input:
        sequences = "data/download_{flu_type}_{segment_name}.fasta"
    output:
        metadata = "pre-processed/metadata_{flu_type}_{segment_name}.tsv",
        sequences = "data/sequences_{flu_type}_{segment_name}.fasta"
    params:
        fields = "ncbiAcc continent country date fluSeason fluType host length state strainName"
    shell:
        """
        augur parse \
            --sequences {input.sequences} \
            --fields {params.fields} \
            --output-metadata {output.metadata} \
            --output-sequences {output.sequences}
        """

genes = ["SigPep","HA1","HA2"]

def flu_type(strain):
    if strain in ["vic","yam"]:
        return "B"
    return "A"

# This should really be read from the builds.yaml/config as the info is present there
def reference(strain):
    type_to_ref = {"h1n1pdm": "KC781785", "h3n2": "CY034116", "vic": "KX058884", "yam": "CY115183"}
    return type_to_ref[strain]

rule prealign:
    input:
        sequences = lambda w: expand(rules.parse.output.sequences,flu_type=flu_type(w.reference),segment_name=w.segment_name),
        genemap = "references/{strain}/{segment_name}/{reference}/genemap.gff",
        reference = "references/{strain}/{segment_name}/{reference}/reference.fasta",
    output:
        alignment = "pre-processed/{strain}/{segment_name}/{reference}/aligned.fasta",
        insertions = "pre-processed/{strain}/{segment_name}/{reference}/insertions.csv",
    params:
        outdir = "pre-processed",
        basename = lambda w: f"{w.reference}_{w.segment_name}",
        genes = lambda w: ",".join(genes(w.reference,w.segment_name)['genes']),
    shell:
        """
        nextalign \
            --reference {input.reference} \
            --genemap {input.genemap} \
            --genes {params.genes} \
            --sequences {input.sequences} \
            --output-dir {params.outdir} \
            --output-basename {params.basename} \
        """

rule mutation_summary:
    message: "Summarizing {input.alignment}"
    input:
        alignment = rules.prealign.output.alignment,
        insertions = rules.prealign.output.insertions,
        # translations = lambda w: expand("pre-processed/{{reference}}_{{segment}}.gene.{genes}.fasta",genes=genes(w.segment)),
        genemap = "references/{strain}/{segment_name}/{reference}/genemap.gff",
        reference = "references/{strain}/{segment_name}/{reference}/reference.fasta",
    output:
        mutation_summary = "pre-processed/{strain}/{segment_name}/{reference}/mutation_summary.tsv"
    params:
        outdir = "pre-processed",
        basename = lambda w: f"{w.reference}_{w.segment_name}",
        genes = lambda w: ",".join(genes(w.reference,w.segment_name)['genes']),
    shell:
        """
        python3 scripts/mutation_summary.py \
            --alignment {input.alignment} \
            --insertions {input.insertions} \
            --directory {params.outdir} \
            --basename {params.basename} \
            --reference {input.reference} \
            --genes {params.genes} \
            --genemap {input.genemap} \
            --output {output.mutation_summary} 2>&1
        """

rule enrich_metadata:
    input:
        metadata = lambda w:  expand(rules.parse.output.metadata,segment_name="ha",flu_type=w.flu_type),
        mutation_summary = lambda w: expand(rules.mutation_summary.output.mutation_summary,strain=(['yam','vic'] if w.flu_type == 'B' else ['h1n1pdm','h3n2']),segment_name="ha",flu_type=w.flu_type)
    output:
        enriched_metadata = "pre-processed/metadata_enriched_{flu_type}.tsv"
    shell:
        """
        python3 scripts/metadata_enrichment.py \
            --flu-type {wildcards.flu_type} \
            2>&1
        """

rule merge_metadata:
    input:
        enriched_metadata = lambda w:  expand(rules.enrich_metadata.output.enriched_metadata,flu_type=w.flu_type),
        metadata = lambda w: expand(rules.parse.output.metadata, segment_name=w.segment_name,flu_type=w.flu_type)
    output:
        merged_metadata = "pre-processed/metadata_enriched_{flu_type}_{segment_name}.tsv"
    shell:
        """
        python3 scripts/merge_metadata.py \
            --flu-type {wildcards.flu_type} \
            --segment {wildcards.segment_name} \
            2>&1
        """

rule subsample:
    input:
        sequences = "pre-processed/{strain}_{segment_name}.aligned.fasta",
        metadata = lambda w: f"pre-processed/metadata_enriched_{flu_type(w.strain)}_{w.segment_name}.tsv",
    output:
        sequences = "build/{strain}/{segment_name}/subsample_raw.fasta",
        strains = "build/{strain}/{segment_name}/subsample_raw.txt",
    params:
        filter_arguments = lambda w: config["filter"][w.strain],
        include = lambda w: config['refine']['root'][w.strain][w.segment],
    resources:
        # Memory use scales primarily with the size of the metadata file.
        mem_mb=lambda wildcards, input: 15 * int(input.metadata.size / 1024 / 1024)
    shell:
        """
        augur filter \
            --sequences {input.sequences} \
            --metadata {input.metadata} \
            --include-where ncbiAcc={params.include} \
            {params.filter_arguments} \
            --output {output.sequences} \
            --output-strains {output.strains} \
            2>&1
        """

rule exclude_outliers:
   input:
       sequences = rules.subsample.output.sequences,
    #    strains = rules.subsample.output.strains,
       metadata =  lambda w: f"pre-processed/metadata_enriched_{flu_type(w.strain)}_{w.segment_name}.tsv",
       exclude = "profiles/exclude.txt",
   output:
       sequences = "build/{strain}/{segment_name}/subsample.fasta",
       strains = "build/{strain}/{segment_name}/subsample.txt",
   params:
       filter_arguments = lambda w: config["filter"][w.strain],
       include = lambda w: config['refine']['root'][w.strain][w.segment_name],
   resources:
       # Memory use scales primarily with the size of the metadata file.
       mem_mb=lambda wildcards, input: 15 * int(input.metadata.size / 1024 / 1024)
   shell:
       """
       augur filter \
           --sequences {input.sequences} \
           --metadata {input.metadata} \
           --exclude {input.exclude} \
           --output {output.sequences} \
           --output-strains {output.strains} \
           2>&1
       """

rule tree:
    message: "Building tree"
    input:
        alignment = rules.exclude_outliers.output.sequences
    output:
        tree = "build/{strain}/{segment_name}/tree_raw.nwk"
    params:
        args = lambda w: config["tree"].get("tree-builder-args","") if "tree" in config else ""
    threads: 4
    resources:
        # Multiple sequence alignments can use up to 40 times their disk size in
        # memory, especially for larger alignments.
        # Note that Snakemake >5.10.0 supports input.size_mb to avoid converting from bytes to MB.
        mem_mb=lambda wildcards, input: 40 * int(input.size / 1024 / 1024)
    shell:
        """
        augur tree \
            --alignment {input.alignment} \
            --tree-builder-args {params.args} \
            --output {output.tree} \
            --nthreads {threads} 2>&1
        """

rule refine:
    message:
        """
        Refining tree
        """
    input:
        tree = rules.tree.output.tree,
        alignment = rules.exclude_outliers.output.sequences,
        metadata = lambda w: f"pre-processed/metadata_enriched_{flu_type(w.strain)}.tsv"
    output:
        tree = "build/{strain}/{segment_name}/{reference}/tree.nwk",
        node_data = "build/{strain}/{segment_name}/{reference}/branch_lengths.json"
    threads: 4
    resources:
        # Multiple sequence alignments can use up to 15 times their disk size in
        # memory.
        # Note that Snakemake >5.10.0 supports input.size_mb to avoid converting from bytes to MB.
        mem_mb=lambda wildcards, input: 15 * int(input.size / 1024 / 1024)
    params:
        root = lambda w: config["refine"]["root"][w.strain][w.segment_name],
        divergence_unit = "mutations-per-site",
    shell:
        """
        augur refine \
            --tree {input.tree} \
            --alignment {input.alignment} \
            --metadata {input.metadata} \
            --output-tree {output.tree} \
            --output-node-data {output.node_data} \
            --root {params.root} \
            --divergence-unit {params.divergence_unit} \
           2>&1
        """

rule ancestral:
    message:
        """
        Reconstructing ancestral sequences and mutations
          - inferring ambiguous mutations
        """
    input:
        tree = rules.refine.output.tree,
        alignment = rules.exclude_outliers.output.sequences,
    output:
        node_data = "build/{strain}/{segment_name}/{reference}/nt_muts.json"
    params:
        inference = "joint"
    resources:
        # Multiple sequence alignments can use up to 15 times their disk size in
        # memory.
        # Note that Snakemake >5.10.0 supports input.size_mb to avoid converting from bytes to MB.
        mem_mb=lambda wildcards, input: 15 * int(input.size / 1024 / 1024)
    shell:
        """
        augur ancestral \
            --tree {input.tree} \
            --alignment {input.alignment} \
            --output-node-data {output.node_data} \
            --inference {params.inference} \
            --infer-ambiguous 2>&1
        """

rule aa_muts_explicit:
    message: "Translating amino acid sequences"
    input:
        tree = rules.refine.output.tree,
        genemap = "references/{strain}/{segment_name}/{reference}/genemap.gff",
        reference = "references/{strain}/{segment_name}/{reference}/reference.fasta",
    output:
        node_data = "build/{strain}/{segment_name}/{reference}/aa_muts_explicit.json",
        # translations = vic.gene.HA_withInternalNodes.fasta
    params:
        # genes = lambda w: genes(w.strain,w.segment)['genes'],
        genes = ["SigPep","HA1","HA2"],
        translations = lambda w: expand("pre-processed/{strain}_{segment_name}.gene.{genes}.fasta",strain=w.strain,segment_name=w.segment_name,genes=["SigPep","HA1","HA2"]),
    resources:
        # Multiple sequence alignments can use up to 15 times their disk size in
        # memory.
        # Note that Snakemake >5.10.0 supports input.size_mb to avoid converting from bytes to MB.
        mem_mb=lambda wildcards, input: 15 * int(input.size / 1024 / 1024)
    shell:
        """
        python3 scripts/explicit_translation.py \
            --tree {input.tree} \
            --annotation {input.genemap} \
            --reference {input.reference} \
            --translations {params.translations:q} \
            --genes {params.genes} \
            --output {output.node_data} 2>&1
        """

rule clades:
    message: "Adding internal clade labels"
    input:
        tree = rules.refine.output.tree,
        aa_muts = rules.aa_muts_explicit.output.node_data,
        nuc_muts = rules.ancestral.output.node_data,
        clades = rules.offset_clades.output
    output:
        node_data = "build/{strain}/{segment_name}/{reference}/clades.json"
    resources:
        # Memory use scales primarily with size of the node data.
        mem_mb=lambda wildcards, input: 3 * int(input.size / 1024 / 1024)
    shell:
        """
        augur clades --tree {input.tree} \
            --mutations {input.nuc_muts} {input.aa_muts} \
            --clades {input.clades} \
            --output-node-data {output.node_data} 2>&1
        """

def node_data(w):
    nodes = ['ancestral','refine','aa_muts_explicit']
    if w.segment_name == "ha":
        nodes.extend(['clades'])
    return nodes

rule export:
    message: "Exporting data files for auspice"
    input:
        tree = rules.refine.output.tree,
        # tree = "build/pruned_tree.nwk,
        metadata = lambda w: expand(rules.merge_metadata.output.merged_metadata,flu_type=flu_type(w.strain),segment_name=w.segment_name),
        node_data = lambda w:
            [rules.__dict__[rule].output.node_data for rule in node_data(w)],
        auspice_config = lambda w: config['files']['auspice_config']
    output:
        auspice_json = "auspice/{strain}/{segment_name}/{reference}/auspice.json",
    params:
        fields = "continent fluSeason strainName" #deleted country"
    resources:
        # Memory use scales primarily with the size of the metadata file.
        mem_mb=100
    shell:
        """
        augur export v2 \
            --tree {input.tree} \
            --metadata {input.metadata} \
            --node-data {input.node_data}\
            --auspice-config {input.auspice_config} \
            --color-by-metadata {params.fields} \
            --output {output.auspice_json} 2>&1;
        """
def segment_no(strain,segment_name) -> str:
    "Return the segment number for a strain and segment name."
    names = [
        "PB2",
        "PB1",
        "PA",
        "HA",
        "NP",
        "NA",
        "MA",
        "NS",
    ]
    segment_no = names.index(segment_name.upper()) + 1
    if strain in ["vic","yam"] and segment_no <= 2:
        if segment_no == 1:
            segment_no = 2
        else:
            segment_no = 1
    return str(segment_no)

#use segment name rather than no all the way through to make things easier
rule generate_sample_sequences:
    input:
        sequences = lambda w: f"pre-processed/{w.strain}_{segment_no(w.strain,w.segment_name)}.aligned.fasta",
        metadata = lambda w: f"pre-processed/metadata_enriched_{flu_type(w.strain)}_{segment_no(w.strain,w.segment_name)}.tsv",
    output:
        sequences = "build/{strain}/{segment_name}/sample_sequences.fasta",
    shell:
        """
        augur filter \
            --sequences {input.sequences} \
            --metadata {input.metadata} \
            --min-date 2019 --exclude-where subtype!='{wildcards.strain}' --group-by continent year --subsample-max-sequences 50  \
            --output {output.sequences} \
            2>&1 | tee {log}
        """

# make segment_no function
rule assemble_folder:
    input:
        genemap = "references/{strain}/{segment_name}/{reference}/genemap.gff",
        reference = "references/{strain}/{segment_name}/{reference}/reference.fasta",
        sample_sequences = "build/{strain}/{segment_name}/sample_sequences.fasta",
        tree = "auspice/{strain}/{segment_name}/{reference}/auspice.json",
        qc = "profiles/qc.json",
        tag = "profiles/tag.json",
        primers = "profiles/primers.csv",
    output:
        genemap = "output/flu_{strain}_{segment_name}/references/{reference}/versions/{timestamp}/files/genemap.gff",
        primers = "output/flu_{strain}_{segment_name}/references/{reference}/versions/{timestamp}/files/primers.csv",
        qc = "output/flu_{strain}_{segment_name}/references/{reference}/versions/{timestamp}/files/qc.json",
        reference = "output/flu_{strain}_{segment_name}/references/{reference}/versions/{timestamp}/files/reference.fasta",
        sample_sequences = "output/flu_{strain}_{segment_name}/references/{reference}/versions/{timestamp}/files/sequences.fasta",
        tree = "output/flu_{strain}_{segment_name}/references/{reference}/versions/{timestamp}/files/tree.json",
        tag = "output/flu_{strain}_{segment_name}/references/{reference}/versions/{timestamp}/files/tag.json",
    shell:
        """
        mkdir -p output/flu_{wildcards.strain}_{wildcards.segment_name}/references/{wildcards.reference}/versions/{wildcards.timestamp}/files/;
        jq <{input.tag} '.tag="{wildcards.timestamp}";
        cp {input.genemap} {output.genemap};
        cp {input.reference} {output.reference};
        cp {input.primers} {output.primers};
        cp {input.qc} {output.qc};
        cp {input.sample_sequences} {output.sample_sequences};
        cp {input.tree} {output.tree};
        """

timestamp = datetime.utcnow().isoformat()[:-7]+'Z'
rule test_nextclade:
    input: expand("output/flu_{{strain}}_{{segment_name}}/references/{{reference}}/versions/{timestamp}/files/tree.json",timestamp=timestamp),
    output: "test/{strain}/{segment_name}/{reference}/nextclade.aligned.fasta"
    params:
        indir = expand("output/flu_{{strain}}_{{segment_name}}/references/{{reference}}/versions/{timestamp}/files",timestamp=timestamp),
        outdir = "test/{strain}/{segment_name}/{reference}"
    shell:
        """
        /Users/cr/code/nextclade/.out/bin/nextclade-MacOS-x86_64 \
         --input-fasta={params.indir}/sequences.fasta\
         --input-root-seq={params.indir}/reference.fasta\
         --genes=SigPep,HA1,HA2\
         --input-qc-config={params.indir}/qc.json\
         --input-gene-map={params.indir}/genemap.gff\
         --input-tree={params.indir}/tree.json\
         --output-dir={params.outdir}\
         --output-tsv={params.outdir}/nextclade.tsv\
         --output-tree={params.outdir}/nextclade.auspice.json\
         --output-basename=nextclade 2>&1
        """
# print(config)
# print(                [f"test/{strain}/{segment_name}/{reference}/nextclade.aligned.fasta" for strain in config["builds"] for segment_name in config["builds"][strain] for reference in config["builds"][strain][segment_name]])
rule all:
    input:
        [f"test/{strain}/{segment_name}/{reference}/nextclade.aligned.fasta" for strain in config["builds"] for segment_name in config["builds"][strain] for reference in config["builds"][strain][segment_name]]

rule clean:
    shell:
        """
        rm -rf output test data/clades*
        """

rule clean_all:
    shell:
        """
        rm -rf output test auspice build pre-processed data/clades*
        """